<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"> 
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <title>Stylianos I. Venieris | Home</title>
        
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
    	<link href="style.css" rel="stylesheet">
		
		<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-80907703-1', 'auto');
			ga('send', 'pageview');

		</script> 
	
	</head>
	
    <body>
        <div class="container">
        	<div class="row header">
        		<div class="col-md-offset-2 col-md-10">
          			<h2>Stylianos I. Venieris</h2>
		          	<h5>PhD Candidate</h5>
					<h5><a href="http://www.imperial.ac.uk/intelligent-digital-systems/">Intelligent Digital Systems Lab (iDSL)</a></h5>
		          	<h5><a href="http://www.imperial.ac.uk/electrical-engineering/research/circuits-and-systems/">Circuits and Systems Group</a></h5>
		          	<h5>Department of Electrical and Electronic Engineering</h5>
		          	<h5>Imperial College London</h5>
		          	<h5>stylianos.venieris10@imperial.ac.uk <a href="mailto:stylianos.venieris10@imperial.ac.uk"><span class="glyphicon glyphicon-envelope"></span></a></h5>
		          	<h5><a href="https://scholar.google.co.uk/citations?user=A1QXa5cAAAAJ&hl=en&oi=ao">Google Scholar</a></h5>
					<h5><a href="https://www.researchgate.net/profile/Stylianos_Venieris">ResearchGate</a></h5>
					<h5><a href="http://dblp.uni-trier.de/pers/hd/v/Venieris:Stylianos_I=">DBLP</a></h5>
					<h5><a href="https://www.linkedin.com/in/stylianos-i-venieris-300446155">LinkedIn</a></h5>
        		</div>
      		</div>
		    <hr/>

      		<div class="row content">
        		<div class="col-lg-offset-2 col-lg-4">
         			<h4>Research Interests</h4>
         			<p style="text-align:justify">My research interests include architectures and methodologies for mapping Machine Learning algorithms 
					to high-performance, energy-efficient reconfigurable FPGA-based systems 
					and making FPGAs more accessible to Artificial Intelligence practitioners. Currently,
					my research focuses on methodologies for the principled and automated mapping of Deep Learning algorithms
					on FPGA-based platforms, including Convolutional Neural Networks and Recurrent Neural Networks.</p> 
					
					<p >My PhD is sponsored by the Engineering and Physical Sciences Research Council (EPSRC).</p>
		  			<p>Supervisor: <strong>Dr. Christos Bouganis</strong><br/>
		  			Web:  <a href="http://cas.ee.ic.ac.uk/people/ccb98">http://cas.ee.ic.ac.uk/people/ccb98</a>
		  			</p>
					
					<h4>fpgaConvNet Toolflow</h4>
					<p>During my PhD, I developed <strong>fpgaConvNet</strong>, a framework 
					for the automated mapping of Convolutional Neural Networks on FPGAs, with details at the following link (<a href="http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html">http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html</a>).
					</p>
         			


          			<h4>Teaching <!--and Supervision -- Experience -->Activities</h4> 
          			<ul>
						<li>PG Teaching Assistant for:
							<ul>
								<li><a href="http://intranet.ee.ic.ac.uk/electricalengineering/eecourses_t4/course_content.asp?c=EE3-05&s=E3#start">Digital System Design</a>, 
								Imperial College London, '15 - Present </li>
								<li><a href="http://intranet.ee.ic.ac.uk/electricalengineering/eecourses_t4/course_content.asp?c=EE9-AC16&s=A1#start">Advanced Digital System Design</a>, 
								Imperial College London, '17 - Present
								<li><a href="http://intranet.ee.ic.ac.uk/electricalengineering/eecourses_t4/course_content.asp?c=EE1-IPRJ&s=I1#start">Electronic & Information Engineering 1st Year Group Project</a>, 
								Imperial College London, 17' - Present</li>
							</ul>
						</li>
						<li>Co-supervisor for:
							<ul>
								<li>master's final year projects</li>
								<li>research summer placements</li>
							</ul>
          			</ul>
		  
		  			<h4>Services</h4>
		  			<ul>
						<li>Reviewer for the ACM Computing Surveys (ACM CSUR)</li>
						<li>Reviewer for the IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
						<li>System administrator of the <a href="http://www.imperial.ac.uk/electrical-engineering/research/circuits-and-systems/">Circuits and Systems Group</a> at Imperial College London, '15 - Present</li>
					</ul>
					
        		</div>
		

        		<div class="col-lg-4">
        			<h4>Background and Short Bio</h4>
          			<!--h4>CV <a href="pg14cv.pdf">.pdf</a></h4-->
          			<ul>
            			<li>MEng in Electrical and Electronic Engineering, Imperial College London</li>
            			<li>Governors' MEng Prize awarded for academic excellence, Imperial College London, '14</li>
               			<li>Engineering Dean's List '12, '13, '14</li>
               			<li>EPSRC Doctoral Training Studentship award, '14</li>
            			<li>Software Developer Intern at
             				<ul>
                				<li><a href="http://portal.singularlogic.eu/">SingularLogic</a>, European Projects Department ('12, 3 months)</li>
              				</ul>
              			</li>
		         	</ul>
        		</div>
      		</div>

 	     	<hr/>

      		<div class="row content">
        		<div class="col-lg-offset-2 col-lg-9 publications">
					<h4>Research Projects</h4>
					<style type="text/css">
						.tg  {border-spacing:0; border:none;}
						.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;overflow:hidden;word-break:normal; text-align:justify;}
						.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
						.tg .tg-031e{text-align:justify}
					</style>
					<table class="tg">
						<tr>
							<td class="tg-031e" valign="top"><a href="fcnnx_arch.png" target="_blank"><img src="fcnnx_arch.png" alt="CNN-to-FPGA Toolflows Chart" width="380px"></a></td>
							<td class="tg-031e">
								<strong>f-CNN<sup>x</sup>: Enabling emerging multi-CNN applications</strong>
								<p>In the construction of complex AI systems, CNN models are used as building blocks of a larger system. 
								In this respect, multi-CNN systems have emerged, employing several models, each one trained for a different subtask. 
								Nevertheless, deploying multiple models on a target platform poses a number of challenges. From a resource allocation perspective, 
								with each model targeting a different task, the performance 
								constraints, such as required throughput and latency, vary accordingly. 
								Instead of being model-agnostic, this property requires the design of an architecture that captures and reflects the performance 
								requirements of each model. Moreover, in resource-constrained setups, multiple CNNs compete for the same pool of resources 
								and hence resource allocation between models becomes a critical factor. 
								f-CNN<sup>x</sup> is a toolflow which addresses the mapping of multiple CNNs on a target FPGA platform 
								while meeting the required performance for each model. Starting from a set of pretrained models, f-CNN<sup>x</sup> explores a wide range of resource and bandwidth 
								allocations and incorporates the application-level importance of each model by means of multiobjective cost functions to guide the design space exploration 
								to the optimum hardware design.</p>
								<p>
									<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="papers/[2018]_fpl_fcnnx_mapping_multiple_cnns_on_fpgas.pdf">f-CNN<sup>x</sup>: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs</a></em>,
									<strong>28th International Conference on Field Programmable Logic and Applications (FPL), 2018.</strong> <br>[<a href="papers/sv2018fpl.bibtex">bibtex</a> | 
									<a href="https://arxiv.org/abs/1805.10174">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8533527">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="toolflows_chart.png" target="_blank"><img src="toolflows_chart.png" alt="CNN-to-FPGA Toolflows Chart" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Landscape of CNN-to-FPGA toolflows and future directions</strong>
								<p>To drive the experimentation and development of novel deep learning models, both industrial and academic institutions have released software frameworks, optimised for training and deploying deep learning models with high compute performance. Currently, frameworks such as Caffe2, PyTorch and CNTK achieve high processing speed by primarily targeting power-hungry CPUs and GPUs. Recently, FPGAs have emerged as a potential alternative platform that can reduce significantly power consumption cost while meeting the compute requirements of modern deep learning systems. In this project, we survey the landscape of toolflows which automate the mapping of the CNN inference stage to FPGA-based platforms. From a deep learning scientist perspective, we conduct a study over the supported deep learning models, including DNNs, CNNs and LSTMs, the achieved processing speed and the applicability of each toolflow on specific deep learning applications, from latency-critical mobile systems to high-throughput cloud services. From a computer engineering perspective, we present a detailed analysis of the architectural choices, design space exploration methods and implementation optimisations of the existing tools, together with insightful discussions. With an eye to the future of FPGA-based deep learning, we present a set of promising areas of research that can bridge the gap between FPGAs and deep learning practitioners and enable FPGAs to provide the necessary compute infrastructure that can drive future deep learning algorithmic innovations.
								</p>
								<p>
									To encourage the meaningful and fair comparison between toolflows, we present a uniform evaluation methodology that includes performance metrics 
									and a <a href="http://www.imperial.ac.uk/intelligent-digital-systems/cnn-benchmark-suite/" target="_blank">benchmark suite </a> that aims to assess the strengths and limitations of each toolflow.
									<a href="http://www.imperial.ac.uk/intelligent-digital-systems/cnn-benchmark-suite/">Read more.</a>
									<br>
								</p>
								<p>
									<strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
									<em><a href="papers/[2018]_acm_csur_toolflows_for_mapping_cnns_on_fpgas_a_survey_and_future_directions.pdf">Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions</a></em>,
									<strong>ACM Computing Surveys, 2018.</strong> <br>[<a href="papers/sv2018csur.bibtex">bibtex</a> | 
									<a href="http://dl.acm.org/citation.cfm?id=3186332">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="fpgaconvnet-flow-1012x532.png" target="_blank"><img src="fpgaconvnet-flow-1012x532.png" alt="fpgaConvNet Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>fpgaConvNet: An automated CNN-to-FPGA toolflow</strong>
								<p>Convolutional Neural Networks (ConvNets/CNNs) are a powerful Deep Learning model which has demonstrated state-of-the-art accuracy in numerous AI tasks, from object detections to neural image captioning. In this context, FPGAs constitute a promising platform for the deployment of ConvNets which can satisfy the demanding performance needs and power constraints posed by emerging applications. Nevertheless, the effective mapping of ConvNets on FPGAs requires Deep Learning practitioners to have expertise in hardware design and familiarity with the esoteric FPGA development toolchains, and therefore poses a significant barrier. fpgaConvNet is a framework that automates the mapping of ConvNets onto reconfigurable FPGA-based platforms. Starting from a high-level description of a ConvNet model, fpgaConvNet considers both the input model's workload and the application-level performance needs, including throughput, latency and multiobjective criteria, in order to generate optimised streaming accelerators tailored for the target FPGA. fpgaConvNet is being developed by the <a href="http://www.imperial.ac.uk/intelligent-digital-systems/">Intelligent Digital Systems Lab (iDSL)</a>.
								<br/>
									<a href="http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html">Read more</a>
								<br>
								</p>
								<p><strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="papers/sv2016fccm.pdf">fpgaConvNet: A Framework for Mapping Convolutional Neural Networks on FPGAs</a></em>, 
									<strong>FCCM 2016.</strong> [<a href="papers/sv2016fccm_slides.pdf">slides</a> | 
									<a href="papers/sv2016fccm.bibtex">bibtex</a> |
									<a href="http://ieeexplore.ieee.org/document/7544745/">link</a> | <a href="http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html">benchmarks</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="approx_lstm_fpga_flow.png" target="_blank"><img src="approx_lstm_fpga_flow.png" alt="Approximate FPGA-based LSTMs Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Approximate FPGA-based LSTMs under limited computation time</strong>
								<p>
									Long Short-Term Memory (LSTM) networks have demonstrated state-of-the-art accuracy in several pattern recognition tasks, with the prominence of Natural Language Processing (NLP) and speech recognition. Nevertheless, as LSTM models increase in complexity and sophistication, so do their computational and memory requirements. Emerging latency-sensitive applications including mobile robots and autonomous vehicles often operate under stringent computation time constraints, where a decision has to be made in real-time. To address this problem, we developed an approximate computing scheme which enables LSTMs to increase their accuracy as a function of the computation time budget, together with an FPGA-based architecture for the high-performance deployment of the approximate LSTMs. By targeting the real-life Neural Image Caption (NIC) model developed by Google, the proposed framework requires 6.65x less time to achieve the same application-level accuracy compared to a baseline implementation, while achieving an average of 25x higher accuracy under the same computation time constraints. This is the first work in the literature to address the deployment of LSTMs under computation time constraints.
								<br></p>
								<p>
									Michalis Rizakis, <strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
									<em><a href="papers/sv2018arc.pdf">Approximate FPGA-based LSTMs under Computation Time Constraints</a></em>,
									<strong>International Symposium on Applied Reconfigurable Computing (ARC), 2018.</strong> <strong>(Best paper nominee)</strong> [<a href="papers/sv2018arc.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/1801.02190">link</a>]<!--<a href="papers/sv2017nips.bibtex">bibtex</a>,-->
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="fpgaconvnet_vs_tx1_power.png" target="_blank"><img src="fpgaconvnet_vs_tx1_power.png" alt="Approximate FPGA-based LSTMs Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Energy-efficient CNN mappings on embedded FPGAs</strong>
								<p>The deployment of large CNNs on mobile and embedded settings is a challenging task due to the strict throughput, latency and power requirements. With conventional parallel architectures, such as embedded CPUs, GPUs and DSPs, reaching the limit of satisfying these constraints, specialised hardware solutions are becoming a necessity. In this work, we present an automated toolflow that maps diverse CNNs, with both regular and irregular structure, to optimised FPGA-based designs, and demonstrate that the generated designs deliver up to 6.65x higher performance than highly optimised embedded GPU designs for the same power budget in embedded settings.
								<br></p>
								<p>
									<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="papers/sv2017nips.pdf">fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural Networks on Embedded FPGAs</a></em>,
									<strong>Workshop on Machine Learning on the Phone and other Consumer Devices (MLPCD), NIPS 2017.</strong> [<a href="papers/sv2017nips.bibtex">bibtex</a> | 
									<a href="http://arxiv.org/abs/1711.08740">link</a> | <a href="papers/sv2017nips_mlpcd_slides.pdf">slides</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="metrics-1197x719.png" target="_blank"><img src="metrics-1197x719.png" alt="Latency-Driven Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Latency-driven design for FPGA-based CNNs</strong>
								<p>The majority of existing CNN implementations, targeting CPUs, GPUs and FPGAs, are optimised with high throughput as the primary objective. Emerging new AI systems, from self-driving cars and UAVs to low response-time, cloud-based analytics services, require the very low-latency execution of several CNN-based tasks without the processing of inputs in batches. To meet these requirements, we place latency at the centre of optimisation and generate latency-optimised hardware designs for the target CNN-FPGA pairs. This is achieved by introducing a latency-driven methodology, which enables the high-performance execution of CNNs without the need for batch processing. The developed approach enables the expansion of the architectural design space, to meet the performance needs of modern latency-sensitive applications and delivers up to 73.54x and 5.61x latency improvements over throughput-optimised designs on AlexNet and VGG-16 respectively.
								<br></p>
								<p><strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="https://tinyurl.com/y9rhz7ls">Latency-Driven Design for FPGA-based Convolutional Neural Networks</a></em>, 
									<strong>FPL 2017.</strong> [<a href="papers/sv2017fpl.bibtex">bibtex</a> | <a href="http://ieeexplore.ieee.org/document/8056828/">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e"></td>
							<td class="tg-031e"></td>
						</tr>
					</table>
        		</div>
      		</div>
			
			<hr/>
			
			<div class="row content">
        		<div class="col-lg-offset-2 col-lg-9 publications">
          			<h4>Publications</h4>
					<div class="well well-sm">
					<h4>Journals</h4>
					<p>
						<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2018]_tnnls_fpgaconvnet_mapping_regular_and_irregular_cnns_on_fpgas.pdf">fpgaConvNet: Mapping Regular and Irregular Convolutional Neural Networks on FPGAs</a></em>,
						<strong>IEEE Transactions on Neural Networks and Learning Systems, 2018.</strong> [<a href="papers/sv2018tnnls.bibtex">bibtex</a> | <a href="https://ieeexplore.ieee.org/document/8401525/">link</a>]
					</p>
					<p>
						<strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2018]_acm_csur_toolflows_for_mapping_cnns_on_fpgas_a_survey_and_future_directions.pdf">Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions</a></em>,
						<strong>ACM Computing Surveys, 2018.</strong> [<a href="papers/sv2018csur.bibtex">bibtex</a> | <a href="https://dl.acm.org/citation.cfm?id=3186332">link</a>]
					</p>
					
					<h4>Conference Proceedings</h4>
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/[2018]_fpl_fcnnx_mapping_multiple_cnns_on_fpgas.pdf">f-CNN<sup>x</sup>: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs</a></em>,
          				<strong>28th International Conference on Field Programmable Logic and Applications (FPL), 2018.</strong> [<a href="papers/sv2018fpl.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/1805.10174" target="_blank">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8533527">link</a>]
          			</p>
					<p>
          				Alexandros Kouris, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/[2018]_cascadecnn_pushing_the_performance_limits_of_quantisation_in_cnns.pdf">CascadeCNN: Pushing the Performance Limits of Quantisation in Convolutional Neural Networks</a></em>,
          				<strong>28th International Conference on Field Programmable Logic and Applications (FPL), 2018.</strong> [<a href="papers/kouris2018fpl.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/1807.05053">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8533486">link</a>]
          			</p>
					<p>
						<strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
						<em><a href="https://www.sigmobile.org/mobisys/2018/workshops/deepmobile18/papers/Deploying_Deep_Neural_Networks_in_the_Embedded_Space.pdf"-->Deploying Deep Neural Networks in the Embedded Space</a></em>,
						<strong>2nd International Workshop on Embedded and Mobile Deep Learning (EMDL), MobiSys, 2018.</strong> [<!--a href="papers/sv2018csur.bibtex">bibtex</a> | --><a href="http://arxiv.org/abs/1806.08616">link</a> | <a href="papers/EMDL_slides_final.pdf">slides</a>]
					</p>
					<p>
          				Alexandros Kouris, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="http://www.sysml.cc/doc/114.pdf">CascadeCNN: Pushing the performance limits of quantisation</a></em>,
          				<strong>SysML, 2018.</strong> [<a href="papers/cascadecnn2018sysml.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/1805.08743">link</a>]
          			</p>
					<p>
          				Michalis Rizakis, <strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2018arc.pdf">Approximate FPGA-based LSTMs under Computation Time Constraints</a></em>,
          				<strong>14th International Symposium on Applied Reconfigurable Computing (ARC), 2018.</strong> <strong>(Best paper nominee)</strong> [<a href="papers/sv2018arc.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/1801.02190">link</a>]
          			</p>
					<p>
          				Christos Kyrkou, George Plastiras, <strong>Stylianos I. Venieris</strong>, Theocharis Theocharides and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/[2018]_date_dronet_efficient_cnn_detector_for_rt_uav_applications.pdf">DroNet: Efficient Convolutional Neural Network Detector for Real-Time UAV Applications</a></em>,
          				<strong>International Conference on Design, Automation and Test in Europe (DATE), 2018.</strong> [<a href="papers/sv2018date.bibtex">bibtex</a> | 
						<a href="https://ieeexplore.ieee.org/document/8342149/">link</a>]
          			</p>
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2017nips.pdf">fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural Networks on Embedded FPGAs</a></em>,
          				<strong>Workshop on Machine Learning on the Phone and other Consumer Devices (MLPCD), NIPS, 2017.</strong> [<a href="papers/sv2017nips.bibtex">bibtex</a> | 
						<a href="http://arxiv.org/abs/1711.08740">link</a> | <a href="papers/sv2017nips_mlpcd_slides.pdf">slides</a>]
          			</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="https://tinyurl.com/y9rhz7ls">Latency-Driven Design for FPGA-based Convolutional Neural Networks</a></em>, 
          				<strong>27th International Conference on Field Programmable Logic and Applications (FPL), 2017.</strong> [<a href="papers/sv2017fpl.bibtex">bibtex</a> | <a href="http://ieeexplore.ieee.org/document/8056828/">link</a>] <!--(<a href="papers/sv2017fpga_poster.pdf">poster</a>, <a href="papers/sv2017fpga.bibtex">bibtex</a>, 
						<a href="http://dl.acm.org/citation.cfm?doid=3020078.3021791">link</a>) -->
          			</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2017fpga_poster.pdf">fpgaConvNet: Automated Mapping of Convolutional Neural Networks on FPGAs</a></em>, 
          				<strong>ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA), 2017.</strong> [<a href="papers/sv2017fpga_poster.pdf">poster</a> | <a href="papers/sv2017fpga.bibtex">bibtex</a> |
						<a href="http://dl.acm.org/citation.cfm?doid=3020078.3021791">link</a>]
          			</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2016fccm.pdf">fpgaConvNet: A Framework for Mapping Convolutional Neural Networks on FPGAs</a></em>, 
          				<!--strong>FCCM 2016</strong--><strong>IEEE 24th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), 2016.</strong> [<a href="papers/sv2016fccm_slides.pdf">slides</a> | 
						<a href="papers/sv2016fccm.bibtex">bibtex</a> |
						<a href="http://ieeexplore.ieee.org/document/7544745/">link</a> | <a href="fpgaConvNet.html">benchmarks</a>]
          			</p>

          			<p>
          				<strong>Stylianos I. Venieris</strong>, Grigorios Mingas and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2015fpl.pdf">Towards Heterogeneous Solvers for Large-Scale Linear Systems</a></em>, 
          				<strong>25th International Conference on Field Programmable Logic and Applications (FPL), 2015.</strong> [<a href="papers/sv2015fpl_slides.pdf">slides</a> | 
          				<a href="papers/sv2016fpl.bibtex">bibtex</a> | <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7293751">link</a>]
          			</p>
		  			</div>
        		</div>
      		</div>

      		<div class="footer discrete">
        		<p>&copy; Stylianos Venieris 2018</p>
      		</div>

    	</div> <!-- /container -->

    	<!-- Latest compiled and minified JavaScript -->
    	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    	<script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.1.1/js/bootstrap.min.js"></script>
    	<script src="http://code.jquery.com/ui/1.10.3/jquery-ui.min.js"></script>
    </body>
</html>
