<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"> 
    <head>
        
        <title>Stylianos I. Venieris | Home</title>
        
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0, user-scalable=no"">
		<meta name="author" content="Stylianos Venieris">
		<meta name="description" content="Samsung AI Center, Cambridge">
		<meta name="og:title" content="Stylianos I. Venieris">
		
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
		<link href="https://use.fontawesome.com/releases/v5.0.6/css/all.css" rel="stylesheet">
    	<link href="style.css" rel="stylesheet">
		
		<script>
			(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
			(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
			})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

			ga('create', 'UA-80907703-1', 'auto');
			ga('send', 'pageview');

		</script> 
		<!--base target="_blank"-->
	</head>
	
	
    <body>
	<nav class="navbar navbar-inverse navbar-fixed-top navbar-default">
		<div class="col-md-offset-3">
		<!--div class="container-fluid"-->
			<div class="navbar-header">
				<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#myNavbar">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</button>
			</div>
			<div class="navbar-collapse collapse" id="myNavbar">
				<ul class="nav navbar-nav navbar-left">
					<li><a href="#about">About</a></li>
					<li><a href="#pubs">Publications</a></li>
					<li><a href="#service">Service</a></li>
					<li><a href="#projects">Research Projects</a></li>
					<li><a href="#press">Press</a></li>
				</ul>
			</div>
		</div>
	</nav>
	
	
	
        <div class="container">
        	<div class="row header">
        		<div class="col-md-offset-2 col-md-10">
          			<h2><a class="anchor" name="about"></a>Stylianos I. Venieris</h2>
		          	<h5>Senior Research Scientist at <a href="https://research.samsung.com/aicenter_cambridge">Samsung AI Center, Cambridge</a></h5>
					<!--h5><a href="https://research.samsung.com/aicenter_cambridge">Samsung AI Center, Cambridge</a></h5-->
		          	<h5>s.venieris@samsung.com <a href="mailto:s.venieris@samsung.com"><span class="glyphicon glyphicon-envelope"></span></a></h5>
		          	<h5><a href="https://scholar.google.co.uk/citations?user=A1QXa5cAAAAJ&hl=en&oi=ao">Google Scholar</a> - <!--/h5-->
					<!--h5--><a href="https://www.researchgate.net/profile/Stylianos_Venieris">ResearchGate</a> - <!--/h5-->
					<!--h5--><a href="http://dblp.uni-trier.de/pers/hd/v/Venieris:Stylianos_I=">DBLP</a> - <!--/h5-->
					<!--h5--><a href="https://www.linkedin.com/in/stylianos-i-venieris-300446155">LinkedIn</a> - <!--/h5-->
					<!--h5--><a href="https://twitter.com/SIVenieris">Twitter</a></h5>

        		</div>
      		</div>
		    <hr/>

			<div class="row content">
				<div class="col-lg-offset-2 col-md-8">
					<p style="text-align:justify;font-size:14px">
						I am currently a Senior Research Scientist at <a href="https://research.samsung.com/aicenter_cambridge">Samsung AI</a>, where I lead the Distributed AI group, focusing on on-device and distributed forms of machine learning. Before, I was a Research Assistant in the <a href="https://www.imperial.ac.uk/intelligent-digital-systems/">Intelligent Digital Systems Lab</a> which is part of the <a href="http://www.imperial.ac.uk/electrical-engineering">Department of Electrical and Electronic Engineering</a> at <a href="http://www.imperial.ac.uk/">Imperial College London</a>. I received my PhD from Imperial College London under the supervision of <a href="http://cas.ee.ic.ac.uk/people/ccb98">Dr. Christos Bouganis</a>.
					</p>
					<!--h4>Research Interests</h4-->
					<p style="text-align:justify;font-size:14px">
						<!--My research interests include the development of principled and automated methodologies for the mapping of deep learning algorithms on mobile and embedded platforms, in addition to the design of custom hardware accelerators and approximate computing techniques for the high-performance, energy-efficent deployment of deep neural networks (DNNs). -->
						My research interests span three primary topics: the development of principled methodologies for the mapping of deep learning algorithms on mobile and embedded platforms; the design of novel end-to-end deep learning systems that robustly meet multiobjective performance requirements; and the design of custom hardware accelerators for the high-performance, energy-efficient deployment of deep neural networks (DNNs).

						
					</p>
					<p style="text-align:justify;font-size:14px">
						During my PhD, I focused on the design of highly optimised hardware accelerators that deliver fast and energy-efficient inference for various types of DNNs (<i>e.g.</i> CNNs, LSTMs), while making FPGAs more accessible to AI practitioners through design automation. In this endeavour, I developed a synchronous dataflow model for analytically capturing DNN workloads, and designed hardware architectures and methodologies for the automated mapping of deep learning models to high-performance, energy-efficient reconfigurable FPGA-based systems.
					</p> 
				</div>
			</div>
      		<div class="row content">
        		<div class="col-lg-offset-2 col-lg-4" style="font-size:14px">
					<h4>fpgaConvNet Toolflow</h4>
					<p>During my PhD, I developed <strong>fpgaConvNet</strong>, a framework 
					for the automated mapping of Convolutional Neural Networks on FPGAs. More details can be found <a href="http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html">here</a>.
					</p>
  
					<h4><a class="anchor" name="service"></a>Service</h4>
		  			<h5>Workshop and tutorial organisation:</h5>
		  			<ul>
		  				<li><a href="https://emdl22.github.io/">6th International Workshop on Embedded and Mobile Deep Learning (EMDL)</a> @ MobiSys 2022</li>
						<li><a href="https://emdl21.github.io/">5th International Workshop on Embedded and Mobile Deep Learning (EMDL)</a> @ MobiSys 2021</li>
		  				<li><a href="https://emdl20.github.io/">4th International Workshop on Embedded and Mobile Deep Learning (EMDL)</a> @ MobiCom 2020</li>
		  				<li><a href="https://sigmobile.org/mobicom/2019/tutorials.php">Tutorial on Computer Architectures and Hardware Acceleration for Deep Learning</a> @ MobiCom 2019</li>
		  			</ul>
					
					<h5>Guest editor:</h5>
					<ul>
						<li>IEEE Network Special Issue (Jan 2022): <a href="papers/[2022]_ieee_network_Guest_Editorial_Bridging_the_Gap_Between_Industry_and_Academia_for_Networking_Research.pdf">Bridging the Gap between Industry and Academia for Networking Reseach</a></li>
					</ul>

		  			<h5>Reviewer for the following journals:</h5>
		  			<ul>
						<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
						<li>Nature Machine Intelligence</li>
						<li>IEEE Transactions on Mobile Computing (TMC)</li>
						<li>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (TCAD)</li>
						<li>Journal of Parallel and Distributed Computing (JPDC)</li>
						<li>ACM Transactions on Architecture and Code Optimization (TACO)</li>
						<li>Journal of Systems Architecture (JSA)</li>
						<li>ACM Transactions on Reconfigurable Technology and Systems (TRETS)</li>
						<li>ACM Computing Surveys (ACM CSUR)</li>
						<li>IEEE Design & Test</li>
						<li>IET Computer & Digital Techniques</li>
						<li>IEEE Embedded Systems Letters (ESL)</li>
						<li>IEEE Access</li>
					</ul>

					<h5>Program Committee Member</h5>
					<ul>
						<li>ACM/IEEE Symposium on Edge Computing (SEC) 2022</li>
						<li>IEEE International Symposium on Field-Programmable Custom Computing Machines (FCCM) 2022</li>
						<li>IEEE International Conference on Field-Programmable Logic and Applications (FPL) 2022</li>
						<li>IEEE International Conference on Application-specific Systems, Architectures and Processors (ASAP) 2022</li>
						<li>IEEE International Conference on Field-Programmable Logic and Applications (FPL) 2021</li>
						<li>1st Workshop on Distributed and Private Machine Learning (DPML), ICLR Workshop, 2021</li>
						<li>1st Workshop on Distributed Machine Learning (DistributedML) 2020</li>
						<li>IEEE International Conference on Field-Programmable Logic and Applications (FPL) 2020</li>
						<li>2nd International Workshop on Challenges in Artificial Intelligence and Machine Learning for Internet of Things (AIChallengeIoT) 2020</li>
						<li>2nd Workshop on Machine Learning on Edge in Sensor Systems (SenSys-ML) 2020</li>
		  				<li>IEEE International Conference on Parallel and Distributed Systems (ICPADS) 2019</li>
		  				<li>2nd Workshop on Machine Learning on Edge in Sensor Systems (SenSys-ML) 2019</li>
		  			</ul>
		  			<h5>External Reviewer</h5>
					<ul>
						<li>ACM/SIGDA Int. Symp. on Field-Programmable Gate Arrays (FPGA) 2021</li>
						<li>IEEE International Conference on Field-Programmable Logic and Applications (FPL) 2019</li>
						<li>ACM/SIGDA Int. Symp. on Field-Programmable Gate Arrays (FPGA) 2019</li>
		  			</ul>
		  			


		  			
					
					<h4>Teaching <!--and Supervision -- Experience -->Activities</h4> 
          			<ul>
						<li>PG Teaching Assistant for:
							<ul>
								<li><a href="http://intranet.ee.ic.ac.uk/electricalengineering/eecourses_t4/course_content.asp?c=EE3-05&s=E3#start">Digital System Design</a>, 
								Imperial College London, '15 - '18 </li>
								<li><a href="http://intranet.ee.ic.ac.uk/electricalengineering/eecourses_t4/course_content.asp?c=EE9-AC16&s=A1#start">Advanced Digital System Design</a>, 
								Imperial College London, '17 - '18
								<li><a href="http://intranet.ee.ic.ac.uk/electricalengineering/eecourses_t4/course_content.asp?c=EE1-IPRJ&s=I1#start">Electronic & Information Engineering 1st Year Group Project</a>, 
								Imperial College London, '17 - '18</li>
							</ul>
						</li>
						<li>Co-supervisor for:
							<ul>
								<li>master's final year projects</li>
								<li>research summer placements</li>
							</ul>
          			</ul>
        		</div>
		

        		<div class="col-lg-4" style="font-size:14px">
        			<a class="twitter-timeline" data-width="400" data-height="300" data-theme="dark" href="https://twitter.com/SIVenieris?ref_src=twsrc%5Etfw">Tweets by SIVenieris</a> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

        			<h4>Background and Short Bio</h4>
          			<!--h4>CV <a href="pg14cv.pdf">.pdf</a></h4-->
          			<ul>
						<li>PhD on Reconfigurable Hardware and Deep Learning, Imperial College London, '18</li>
            			<li>MEng in Electrical and Electronic Engineering, Imperial College London, '14</li>
            			<li>Governors' MEng Prize awarded for academic excellence, Imperial College London, '14</li>
               			<li>Engineering Dean's List '12, '13, '14</li>
               			<li>EPSRC Doctoral Training Studentship award, '14</li>
            			<li>Software Developer Intern at
             				<ul>
                				<li><a href="http://portal.singularlogic.eu/">SingularLogic</a>, European Projects Department ('12, 3 months)</li>
              				</ul>
              			</li>
		         	</ul>

		         	<h4><a class="anchor" name="press"></a>Press</h4>
		         	<ul>
		         		<li>The Next Platform, July 2020 - <a href="https://www.nextplatform.com/2020/07/14/next-platform-tv-for-july-14-2020/">Interview on using FPGAs for AI training</a> [<a href="https://www.youtube.com/watch?v=arVdQTsMETo&t=878s">video</a>]</li>
		         		<li>EE Journal, August 2018 - <a href="https://www.eejournal.com/article/wheres-the-cnn-synthesis/">"Where’s the CNN Synthesis? Is EDA Missing a Market?"</a></li>
		         	</ul>
        		</div>
      		</div>

 	     	<hr/>

      		<div class="row content">
        		<div class="col-lg-offset-2 col-lg-9">
					<h4><a class="anchor" name="projects"></a>Research Projects</h4>
					<style type="text/css">
						.tg  {border-spacing:0; border:none;}
						.tg td{font: 400 16px/1.5 -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";font-size:14px;padding:10px 5px;overflow:hidden;word-break:normal; text-align:justify;}
						<!-- font-family:Arial, sans-serif; -->
						.tg th{font: 400 16px/1.5 -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;}
						<!-- font-family:Arial, sans-serif; -->
						.tg .tg-031e{text-align:justify}
					</style>
					<table class="tg" style="font-size:14px">
						<tr>
							<td class="tg-031e" valign="top"><a href="unzipfpga_arch.png" target="_blank"><img src="unzipfpga_arch.png" alt="Enhanced CNN engines with unzipFPGA." width="380px"></a>
							</td>
							<td class="tg-031e">
								<strong>unzipFPGA: Mitigating Memory Wall Effects in CNN Engines with On-the-Fly Weights Generation</strong>
								<p>
								One of the most widely adopted paradigms that lies in the midpoint of the flexibility-customisation spectrum is the single computation engine (SCE). Under this paradigm, a powerful processing engine is time-shared to sequentially execute the layers of a CNN. This allows for accelerator’s resources to be reused across both layers and CNN models, without the need to reconfigure the fabric. Nonetheless, their attainable performance is often bounded by two primary factors: 1) layers with low computation-to-communication ratio that become memory-bound and 2) the suboptimal mapping of diverse layers on the fixed configuration of the SCE that leads to underutilised processing elements (PEs). In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at run time. We refer to these approaches as <i>on-the-fly</i>. To minimise the negative impact of limited bandwidth on memory-bound layers, we present a novel hardware component that enables the on-chip on-the-fly generation of weights. We further introduce an input selective PE design that balances the load between PEs on suboptimally mapped layers. Finally, we present unzipFPGA, a framework to train on-the-fly models and traverse the design space to select the highest performing CNN engine configuration. Quantitative evaluation shows that unzipFPGA yields an average of 2.57× performance efficiency gain over highly optimised GPU designs under the same power constraints and up to 3.94× higher performance density over the state-of-the-art FPGA-based CNN accelerators.</p>
								<p>
									<strong>Stylianos I. Venieris</strong>, Javier Fernandez-Marques and Nicholas D. Lane<br/>
									<em><a href="papers/[2021]_fccm_unzipfpga_enhancing_fpga_based_cnn_engines_with_on_the_fly_weights_generation.pdf">unzipFPGA: Enhancing FPGA-based CNN Engines with On-the-Fly Weights Generation</a></em>,
									<strong>29th IEEE International Symposium on Field-Programmable Custom Computing Machines (FCCM), 2021.</strong> [<a href="papers/unzipfpga2021fccm.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2103.05600">preprint</a> | <a href="https://ieeexplore.ieee.org/document/9444081">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="neural_enhancement_systems.png" target="_blank"><img src="neural_enhancement_systems.png" alt="DNN-based visual content delivery systems." width="380px"></a>
							</td>
							<td class="tg-031e">
								<strong>Neural Enhancement for Visual Content Streaming Systems: A Survey and the Road Ahead</strong>
								<p>
								Internet-enabled smartphones and ultra-wide displays are transforming a variety of visual apps spanning from on-demand movies and 360° videos to video-conferencing and live streaming. However, robustly delivering visual content under fluctuating networking conditions on devices of diverse capabilities remains an open problem. In recent years, advances in the field of deep learning on tasks such as superresolution and image enhancement have led to unprecedented performance in generating high-quality images from low-quality ones, a processwe refer to as <i>neural enhancement</i>. In this paper, we survey state-of-the-art content delivery systems that employ neural enhancement as a key component in achieving both fast response time and high visual quality. We first present the deployment challenges of neural enhancement models. We then cover systems targeting diverse use-cases and analyze their design decisions in overcoming technical challenges. Moreover, we present promising directions based on the latest insights from deep learning research to further boost the quality of experience of these systems.</p>
								<p>
									Royson Lee, <strong>Stylianos I. Venieris</strong> and Nicholas D. Lane<br/>
									<em><a href="papers/[2021]_csur_dnn_based_enhancement_for_img_and_vid_streaming_systems.pdf">Deep Neural Network-based Enhancement for Image and Video Streaming Systems: A Survey and Future Directions</a></em>,
									<strong>ACM Computing Surveys (CSUR), 2021.</strong> [<a href="papers/dnn_cds2021csur.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/2106.03727">preprint</a>] <!--[<a href="papers/sv2018csur.bibtex" target="_blank">bibtex</a> | <a href="https://dl.acm.org/citation.cfm?id=3186332">link</a>]-->
					</p>
							</td>
						</tr>						
						<tr>
							<td class="tg-031e" valign="top"><a href="hapi.png" target="_blank"><img src="hapi.png" alt="Hardware-aware progressive inference with HAPI." width="380px"></a>
							</td>
							<td class="tg-031e">
								<strong>HAPI: Hardware-aware design of multi-exit progressive CNNs</strong>
								<p>
								Multi-exit CNNs, or progressive inference networks, are becoming an emerging approach for delivering inference with an adaptive accuracy-complexity trade-off. Nevertheless, existing studies on early exiting have primarily focused on the training scheme, without considering the use-case requirements or the deployment platform. This work presents HAPI, a hardware-aware methodology for generating optimised high-performance multi-exit networks. At its core lies a synchronous dataflow modelling framework that, in contrast to conventional modelling for *static* CNNs, is capable of capturing the *dynamic* conditional execution of multi-exit CNNs. By explicitly considering the target hardware, HAPI efficiently traverses the design space and yields a multi-exit network, tailored to the application's multi-objective needs. Quantitative evaluation shows that our system consistently outperforms alternative search mechanisms and state-of-the-art early-exit schemes across various latency budgets. Moreover, it pushes further the performance of highly optimised hand-crafted early-exit CNNs, delivering up to 5.11× speedup over lightweight models on imposed latency-driven SLAs for embedded  devices. Overall, this work shows how multi-exit CNNs together with hardware-aware customisation can be key enablers for meeting the performance goals of AI applications across diverse platforms.</p>
								<p>
									Stefanos Laskaridis, <strong>Stylianos I. Venieris</strong>, Hyeji Kim and Nicholas D. Lane<br/>
									<em><a href="papers/[2020]_iccad_hapi_hardware_aware_progressive_inference.pdf">HAPI: Hardware-Aware Progressive Inference</a></em>,
									<strong>IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2020.</strong> [<a href="papers/hapi2020iccad.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2008.03997">preprint</a>]		
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="spinn.png" target="_blank"><img src="spinn.png" alt="Distributed inference with SPINN." width="380px"></a>
							</td>
							<td class="tg-031e">
								<strong>SPINN: Robust distributed inference through multi-exit progressive models and device-server synergy</strong>
								<p>Despite the soaring use of convolutional neural networks (CNNs) in mobile applications, uniformly sustaining high-performance inference on mobile has been elusive due to the excessive computational demands of modern CNNs and the increasing diversity of deployed devices. A popular alternative comprises offloading CNN processing to powerful cloud-based servers. Nevertheless, by relying on the cloud to produce outputs, emerging mission-critical and high-mobility applications, such as drone obstacle avoidance or interactive applications, can suffer from the dynamic connectivity conditions and the uncertain availability of the cloud. In this paper, we propose SPINN, a distributed inference system that employs synergistic device-cloud computation together with a progressive inference method to deliver fast and robust CNN inference across diverse settings. The proposed system introduces a novel scheduler that co-optimises the early-exit policy and the CNN splitting at run time, in order to adapt to dynamic conditions and meet user-defined service-level requirements. Quantitative evaluation illustrates that SPINN outperforms its state-of-the-art collaborative inference counterparts by up to 2× in achieved throughput under varying network conditions, reduces the server cost by up to 6.8× and improves accuracy by 20.7% under latency constraints, while providing robust operation under uncertain connectivity conditions and significant energy savings compared to cloud-centric execution.</p>
								<p>
									Stefanos Laskaridis, <strong>Stylianos I. Venieris</strong>, Mario Almeida, Ilias Leontiadis and Nicholas D. Lane<br/>
									<em><a href="papers/[2020]_mobicom_spinn_synergistic_progressive_inference_of_neural_networks_over_device_and_cloud.pdf">SPINN: Synergistic Progressive Inference of Neural Networks over Device and Cloud</a></em>,
									<strong>26th Annual International Conference on Mobile Computing and Networking (MobiCom), 2020.</strong> [<a href="papers/spinn2020mobicom.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2008.06402">preprint</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="mobisr.png" target="_blank"><img src="mobisr.png" alt="MobiSR system architecture." width="380px"></a>
							</td>
							<td class="tg-031e">
								<strong>MobiSR: Delivering high-performance on-device super-resolution through heterogeneous mobile processors</strong>
								<p>In recent years, convolutional networks have demonstrated unprecedented performance in the image restoration task of super-resolution (SR). SR entails the upscaling of a single low-resolution image in order to meet application-specific image quality demands and plays a key role in mobile devices. To comply with privacy regulations and reduce the overhead of cloud computing, executing SR models locally on-device constitutes a key alternative approach. Nevertheless, the excessive compute and memory requirements of SR workloads pose a challenge in mapping SR networks on resource-constrained mobile platforms. This work presents MobiSR, a novel framework for performing efficient superresolution on-device. Given a target mobile platform, the proposed framework considers popular model compression techniques and traverses the design space to reach the highest performing trade-off between image quality and processing speed. At run time, a novel scheduler dispatches incoming image patches to the appropriate model-engine pair based on the patch’s estimated upscaling difficulty in order to meet the required image quality with minimum processing latency. Quantitative evaluation shows that the proposed framework yields on-device SR designs that achieve an average speedup of 2.13× over highly-optimized parallel difficulty-unaware mappings and 4.79× over highly-optimized single compute engine implementations.</p>
								<p>
									Royson Lee, <strong>Stylianos I. Venieris</strong>, Lukasz Dudziak, Sourav Bhattacharya and Nicholas D. Lane<br/>
									<em><a href="papers/[2019]_mobicom_mobisr_efficient_on_device_super_resolution_through_heterogeneous_mobile_processors.pdf">MobiSr: Efficient On-Device Super-resolution through Heterogeneous Mobile Processors</a></em>,
									<strong>25th Annual International Conference on Mobile Computing and Networking (MobiCom), 2019.</strong> [<a href="papers/lee2019mobicom.bibtex">bibtex</a> | <a href="https://dl.acm.org/citation.cfm?id=3345455">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="fcnnx_arch.png" target="_blank"><img src="fcnnx_arch.png" alt="CNN-to-FPGA Toolflows Chart" width="380px"></a></td>
							<td class="tg-031e">
								<strong>f-CNN<sup>x</sup>: Enabling emerging multi-CNN applications</strong>
								<p>In the construction of complex AI systems, CNN models are used as building blocks of a larger system. 
								In this respect, multi-CNN systems have emerged, employing several models, each one trained for a different subtask. 
								Nevertheless, deploying multiple models on a target platform poses a number of challenges. From a resource allocation perspective, 
								with each model targeting a different task, the performance 
								constraints, such as required throughput and latency, vary accordingly. 
								Instead of being model-agnostic, this property requires the design of an architecture that captures and reflects the performance 
								requirements of each model. Moreover, in resource-constrained setups, multiple CNNs compete for the same pool of resources 
								and hence resource allocation between models becomes a critical factor. 
								f-CNN<sup>x</sup> is a toolflow which addresses the mapping of multiple CNNs on a target FPGA platform 
								while meeting the required performance for each model. Starting from a set of pretrained models, f-CNN<sup>x</sup> explores a wide range of resource and bandwidth 
								allocations and incorporates the application-level importance of each model by means of multiobjective cost functions to guide the design space exploration 
								to the optimum hardware design.</p>
								<p>
									<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="papers/[2018]_fpl_fcnnx_mapping_multiple_cnns_on_fpgas.pdf">f-CNN<sup>x</sup>: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs</a></em>,
									<strong>28th International Conference on Field Programmable Logic and Applications (FPL), 2018.</strong> <br>[<a href="papers/sv2018fpl.bibtex" target="_blank">bibtex</a> | 
									<a href="https://arxiv.org/abs/1805.10174">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8533527">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="toolflows_chart.png" target="_blank"><img src="toolflows_chart.png" alt="CNN-to-FPGA Toolflows Chart" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Landscape of CNN-to-FPGA toolflows and future directions</strong>
								<p>To drive the experimentation and development of novel deep learning models, both industrial and academic institutions have released software frameworks, optimised for training and deploying deep learning models with high compute performance. Currently, frameworks such as Caffe2, PyTorch and CNTK achieve high processing speed by primarily targeting power-hungry CPUs and GPUs. Recently, FPGAs have emerged as a potential alternative platform that can reduce significantly power consumption cost while meeting the compute requirements of modern deep learning systems. In this project, we survey the landscape of toolflows which automate the mapping of the CNN inference stage to FPGA-based platforms. From a deep learning scientist perspective, we conduct a study over the supported deep learning models, including DNNs, CNNs and LSTMs, the achieved processing speed and the applicability of each toolflow on specific deep learning applications, from latency-critical mobile systems to high-throughput cloud services. From a computer engineering perspective, we present a detailed analysis of the architectural choices, design space exploration methods and implementation optimisations of the existing tools, together with insightful discussions. With an eye to the future of FPGA-based deep learning, we present a set of promising areas of research that can bridge the gap between FPGAs and deep learning practitioners and enable FPGAs to provide the necessary compute infrastructure that can drive future deep learning algorithmic innovations.
								</p>
								<p>
									To encourage the meaningful and fair comparison between toolflows, we present a uniform evaluation methodology that includes performance metrics 
									and a <a href="http://www.imperial.ac.uk/intelligent-digital-systems/cnn-benchmark-suite/" target="_blank">benchmark suite </a> that aims to assess the strengths and limitations of each toolflow.
									<a href="http://www.imperial.ac.uk/intelligent-digital-systems/cnn-benchmark-suite/">Read more.</a>
									<br>
								</p>
								<p>
									<strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
									<em><a href="papers/[2018]_acm_csur_toolflows_for_mapping_cnns_on_fpgas_a_survey_and_future_directions.pdf">Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions</a></em>,
									<strong>ACM Computing Surveys, 2018.</strong> <br>[<a href="papers/sv2018csur.bibtex" target="_blank">bibtex</a> | 
									<a href="http://dl.acm.org/citation.cfm?id=3186332">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="fpgaconvnet-flow-1012x532.png" target="_blank"><img src="fpgaconvnet-flow-1012x532.png" alt="fpgaConvNet Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>fpgaConvNet: An automated CNN-to-FPGA toolflow</strong>
								<p>Convolutional Neural Networks (ConvNets/CNNs) are a powerful Deep Learning model which has demonstrated state-of-the-art accuracy in numerous AI tasks, from object detections to neural image captioning. In this context, FPGAs constitute a promising platform for the deployment of ConvNets which can satisfy the demanding performance needs and power constraints posed by emerging applications. Nevertheless, the effective mapping of ConvNets on FPGAs requires Deep Learning practitioners to have expertise in hardware design and familiarity with the esoteric FPGA development toolchains, and therefore poses a significant barrier. fpgaConvNet is a framework that automates the mapping of ConvNets onto reconfigurable FPGA-based platforms. Starting from a high-level description of a ConvNet model, fpgaConvNet considers both the input model's workload and the application-level performance needs, including throughput, latency and multiobjective criteria, in order to generate optimised streaming accelerators tailored for the target FPGA. fpgaConvNet is being developed by the <a href="http://www.imperial.ac.uk/intelligent-digital-systems/">Intelligent Digital Systems Lab (iDSL)</a>.
								<br/>
									<a href="http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html">Read more</a>
								<br>
								</p>
								<p><strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="papers/sv2016fccm.pdf">fpgaConvNet: A Framework for Mapping Convolutional Neural Networks on FPGAs</a></em>, 
									<strong>FCCM 2016.</strong> [<a href="papers/sv2016fccm_slides.pdf">slides</a> | 
									<a href="papers/sv2016fccm.bibtex" target="_blank">bibtex</a> |
									<a href="http://ieeexplore.ieee.org/document/7544745/">link</a> | <a href="http://cas.ee.ic.ac.uk/people/sv1310/fpgaConvNet.html">benchmarks</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="approx_lstm_fpga_flow.png" target="_blank"><img src="approx_lstm_fpga_flow.png" alt="Approximate FPGA-based LSTMs Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Approximate FPGA-based LSTMs under limited computation time</strong>
								<p>
									Long Short-Term Memory (LSTM) networks have demonstrated state-of-the-art accuracy in several pattern recognition tasks, with the prominence of Natural Language Processing (NLP) and speech recognition. Nevertheless, as LSTM models increase in complexity and sophistication, so do their computational and memory requirements. Emerging latency-sensitive applications including mobile robots and autonomous vehicles often operate under stringent computation time constraints, where a decision has to be made in real-time. To address this problem, we developed an approximate computing scheme which enables LSTMs to increase their accuracy as a function of the computation time budget, together with an FPGA-based architecture for the high-performance deployment of the approximate LSTMs. By targeting the real-life Neural Image Caption (NIC) model developed by Google, the proposed framework requires 6.65x less time to achieve the same application-level accuracy compared to a baseline implementation, while achieving an average of 25x higher accuracy under the same computation time constraints. This is the first work in the literature to address the deployment of LSTMs under computation time constraints.
								<br></p>
								<p>
									Michalis Rizakis, <strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
									<em><a href="papers/sv2018arc.pdf">Approximate FPGA-based LSTMs under Computation Time Constraints</a></em>,
									<strong>International Symposium on Applied Reconfigurable Computing (ARC), 2018.</strong> <strong>(Best paper nominee)</strong> [<a href="papers/sv2018arc.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/1801.02190">link</a>]<!--<a href="papers/sv2017nips.bibtex">bibtex</a>,-->
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="fpgaconvnet_vs_tx1_power.png" target="_blank"><img src="fpgaconvnet_vs_tx1_power.png" alt="Approximate FPGA-based LSTMs Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Energy-efficient CNN mappings on embedded FPGAs</strong>
								<p>The deployment of large CNNs on mobile and embedded settings is a challenging task due to the strict throughput, latency and power requirements. With conventional parallel architectures, such as embedded CPUs, GPUs and DSPs, reaching the limit of satisfying these constraints, specialised hardware solutions are becoming a necessity. In this work, we present an automated toolflow that maps diverse CNNs, with both regular and irregular structure, to optimised FPGA-based designs, and demonstrate that the generated designs deliver up to 6.65x higher performance than highly optimised embedded GPU designs for the same power budget in embedded settings.
								<br></p>
								<p>
									<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="papers/sv2017nips.pdf">fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural Networks on Embedded FPGAs</a></em>,
									<strong>Workshop on Machine Learning on the Phone and other Consumer Devices (MLPCD), NIPS 2017.</strong> [<a href="papers/sv2017nips.bibtex">bibtex</a> | 
									<a href="http://arxiv.org/abs/1711.08740">link</a> | <a href="papers/sv2017nips_mlpcd_slides.pdf">slides</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e" valign="top"><a href="metrics-1197x719.png" target="_blank"><img src="metrics-1197x719.png" alt="Latency-Driven Flow" width="380px"></a></td>
							<td class="tg-031e">
								<strong>Latency-driven design for FPGA-based CNNs</strong>
								<p>The majority of existing CNN implementations, targeting CPUs, GPUs and FPGAs, are optimised with high throughput as the primary objective. Emerging new AI systems, from self-driving cars and UAVs to low response-time, cloud-based analytics services, require the very low-latency execution of several CNN-based tasks without the processing of inputs in batches. To meet these requirements, we place latency at the centre of optimisation and generate latency-optimised hardware designs for the target CNN-FPGA pairs. This is achieved by introducing a latency-driven methodology, which enables the high-performance execution of CNNs without the need for batch processing. The developed approach enables the expansion of the architectural design space, to meet the performance needs of modern latency-sensitive applications and delivers up to 73.54x and 5.61x latency improvements over throughput-optimised designs on AlexNet and VGG-16 respectively.
								<br></p>
								<p><strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
									<em><a href="https://tinyurl.com/y9rhz7ls">Latency-Driven Design for FPGA-based Convolutional Neural Networks</a></em>, 
									<strong>FPL 2017.</strong> [<a href="papers/sv2017fpl.bibtex" target="_blank">bibtex</a> | <a href="http://ieeexplore.ieee.org/document/8056828/">link</a>]
								</p>
							</td>
						</tr>
						<tr>
							<td class="tg-031e"></td>
							<td class="tg-031e"></td>
						</tr>
					</table>
        		</div>
      		</div>
			
			<hr/>
			
			<div class="row content">
        		<div class="col-lg-offset-2 col-lg-9 publications">
          			<h4><a class="anchor" name="pubs"></a>Publications</h4>
					<div class="well well-sm">
					<h4>Journals</h4>
					<p>
						<strong>Stylianos I. Venieris</strong>, Christos-Savvas Bouganis and Nicholas D. Lane<br/>
						<em><a href="papers/[2022]_ieee_computer_Multi_DNN_Accelerators_for_Next_Gen_AI_Systems.pdf">Multi-DNN Accelerators for Next-Generation AI Systems</a></em>,
						<strong>IEEE Computer, 2022.</strong> [<a href="papers/multidnn2022mc.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/2205.09376">preprint</a>]<!-- | <a href="https://ieeexplore.ieee.org/document/8401525/">link</a>]-->
					</p>
					<p>
						Mario Almeida*, Stefanos Laskaridis*, <strong>Stylianos I. Venieris*</strong>, Ilias Leontiadis* and Nicholas D. Lane<br/>
						<em><a href="papers/[2022]_tecs_dyno_dynamic_onloading_of_dnns_from_cloud_to_device.pdf">DynO: Dynamic Onloading of Deep Neural Networks from Cloud to Device</a></em>,
						<strong>Special Issue on Accelerating AI on the Edge, ACM Transactions on Embedded Computing Systems (TECS), 2022.</strong> [<a href="papers/dyno2022tecs.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2104.09949">preprint</a> | <a href="https://dl.acm.org/doi/abs/10.1145/3510831">link</a><!-- | <a href="https://youtu.be/wmCNVt-NQd0">video</a-->]
					</p>
					<p>
						Royson Lee*, <strong>Stylianos I. Venieris*</strong> and Nicholas D. Lane<br/>
						<em><a href="papers/[2021]_csur_dnn_based_enhancement_for_img_and_vid_streaming_systems.pdf">Deep Neural Network-based Enhancement for Image and Video Streaming Systems: A Survey and Future Directions</a></em>,
						<strong>ACM Computing Surveys (CSUR), 2021.</strong> [<a href="papers/dnn_cds2021csur.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/2106.03727">preprint</a> | <a href="https://dl.acm.org/doi/abs/10.1145/3469094">link</a>] <!--[<a href="papers/sv2018csur.bibtex" target="_blank">bibtex</a> | <a href="https://dl.acm.org/citation.cfm?id=3186332">link</a>]-->
					</p>
					<p>
						Sourav Bhattacharya, Dionysis Manousakas, Alberto Gil Ramos, <strong>Stylianos I. Venieris</strong>, Nicholas D. Lane, Cecilia Mascolo<br/>
						<em><a href="papers/[2020]_imwut_countering_acoustic_adversarial_attacks_in_mic_equipped_smart_home_devices.pdf">Countering Acoustic Adversarial Attacks in Microphone-equipped Smart Home Devices</a></em>,
						<strong>Proc. of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT/UbiComp), 2020.</strong> [<a href="https://dl.acm.org/doi/abs/10.1145/3397332">link</a> | <a href="https://youtu.be/f0HF9YrIsKI">video</a>]
					</p>
					<p>
						Alexandros Kouris, <strong>Stylianos I. Venieris</strong>, Michalis Rizakis and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2020]_cemag_approx_lstms_for_time_constrained_inference_enabling_fast_reaction_in_self_driving_cars.pdf">Approximate LSTMs for Time-Constrained Inference: Enabling Fast Reaction in Self-Driving Cars</a></em>,
						<strong>IEEE Consumer Electronics Magazine (CEM), 2020.</strong> [<a href="papers/kouris2020cemag.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/1905.00689">preprint</a> | <a href="https://ieeexplore.ieee.org/document/9109418">link</a>]
					</p>
					<p>
						<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2019]_tnnls_fpgaconvnet_mapping_regular_and_irregular_cnns_on_fpgas.pdf">fpgaConvNet: Mapping Regular and Irregular Convolutional Neural Networks on FPGAs</a></em>,
						<strong>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2019.</strong> [<a href="papers/sv2019tnnls.bibtex" target="_blank">bibtex</a> | <a href="https://ieeexplore.ieee.org/document/8401525/">link</a>]
					</p>
					<p>
						<strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2018]_acm_csur_toolflows_for_mapping_cnns_on_fpgas_a_survey_and_future_directions.pdf">Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey and Future Directions</a></em>,
						<strong>ACM Computing Surveys (CSUR), 2018.</strong> [<a href="papers/sv2018csur.bibtex" target="_blank">bibtex</a> | <a href="https://dl.acm.org/citation.cfm?id=3186332">link</a>]
					</p>
					
					<h4>Conference Papers</h4>
					<p>
						Alexandros Kouris, <strong>Stylianos I. Venieris</strong>, Stefanos Laskaridis and Nicholas D. Lane<br/>
						<em><!--a href="papers/[2022]_eccv_multi_exit_semantic_segmentation_networks.pdf"-->Multi-Exit Semantic Segmentation Networks<!--/a--></em>,
						<strong>18th European Conference on Computer Vision (ECCV), 2022.</strong> [<a href="papers/mess2022eccv.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2106.03527">preprint</a>]
					</p>
					<p>
						Alexandros Kouris, <strong>Stylianos I. Venieris</strong>, Stefanos Laskaridis and Nicholas D. Lane<br/>
						<em><!--a href="papers/[2022]_eccv_multi_exit_semantic_segmentation_networks.pdf"-->	
						Poster: Adaptable Mobile Vision Systems through Multi-Exit Neural Networks<!--/a--></em>,
						<strong>20th Annual International Conference on Mobile Systems, Applications and Services (MobiSys), 2022.</strong> [<a href="papers/[2022]_mobisys_mess_poster.pdf">poster</a> | <a href="https://dl.acm.org/doi/abs/10.1145/3498361.3538791">link</a>]
					</p>
					<p>
						Samuel Horvath*, Stefanos Laskaridis*, Mario Almeida, Ilias Leontiadis, <strong>Stylianos I. Venieris</strong> and Nicholas D. Lane<br/>
						<em><a href="papers/[2021]_neurips_fjord_fair_and_accurate_fl_under_heterogeneous_targets_w_ordered_dropout.pdf">FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout</a></em>,
						<strong>35th Conference on Neural Information Processing Systems (NeurIPS), 2021.</strong> <strong>(Spotlight)</strong> [<!--a href="papers/real_time_ai2021asap.bibtex">bibtex</a> | --><a href="https://arxiv.org/abs/2102.13451">preprint</a> | <a href="https://papers.nips.cc/paper/2021/hash/6aed000af86a084f9cb0264161e29dd3-Abstract.html">link</a> | <a href="https://research.samsung.com/blog/FjORD_Fair_and_Accurate_Federated_Learning_under_heterogeneous_targets_with_Ordered_Dropout">blog</a>]
					</p>
					<p>
						<strong>Stylianos I. Venieris</strong>, Ioannis Panopoulos, Ilias Leontiadis and Iakovos S. Venieris<br/>
						<em><a href="papers/[2021]_asap_how_to_reach_real_time_ai.pdf">How to Reach Real-Time AI on Consumer Devices? Solutions for Programmable and Custom Architectures (Invited Paper)</a></em>,
						<strong>32nd IEEE International Conference on Application-specific Systems, Architectures and Processors (ASAP), 2021.</strong> [<a href="papers/real_time_ai2021asap.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2106.15021">preprint</a> | <a href="https://ieeexplore.ieee.org/document/9516652">link</a>]
					</p>
					<p>
						<strong>Stylianos I. Venieris</strong>, Ioannis Panopoulos and Iakovos S. Venieris<br/>
						<em><a href="papers/[2021]_smartcomp_oodin_an_optimised_ondevice_inference_framework_for_heterogeneous_mobile_devices.pdf">OODIn: An Optimised On-Device Inference Framework for Heterogeneous Mobile Devices</a></em>,
						<strong>7th IEEE International Conference on Smart Computing (SMARTCOMP), 2021.</strong>  [<a href="papers/oodin2021smartcomp.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2106.04723">preprint</a> | <a href="https://ieeexplore.ieee.org/document/9556280">link</a>] 
					</p>
					<p>
						<strong>Stylianos I. Venieris*</strong>, Javier Fernandez-Marques* and Nicholas D. Lane<br/>
						<em><a href="papers/[2021]_fccm_unzipfpga_enhancing_fpga_based_cnn_engines_with_on_the_fly_weights_generation.pdf">unzipFPGA: Enhancing FPGA-based CNN Engines with On-the-Fly Weights Generation</a></em>,
						<strong>29th IEEE International Symposium on Field-Programmable Custom Computing Machines (FCCM), 2021.</strong> [<a href="papers/unzipfpga2021fccm.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2103.05600">preprint</a> | <a href="https://ieeexplore.ieee.org/document/9444081">link</a>]
					</p>
					<p>
						Stefanos Laskaridis*, <strong>Stylianos I. Venieris*</strong>, Hyeji Kim and Nicholas D. Lane<br/>
						<em><a href="papers/[2020]_iccad_hapi_hardware_aware_progressive_inference.pdf">HAPI: Hardware-Aware Progressive Inference</a></em>,
						<strong>IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2020.</strong> [<a href="papers/hapi2020iccad.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2008.03997">preprint</a> | <a href="https://ieeexplore.ieee.org/document/9256461/">link</a>] <!--| <a href="https://github.com/ICIdsl/pytorch_training.git">open-source repo</a>]-->
					</p>
					<p>
						Stefanos Laskaridis*, <strong>Stylianos I. Venieris*</strong>, Mario Almeida*, Ilias Leontiadis* and Nicholas D. Lane<br/>
						<em><a href="papers/[2020]_mobicom_spinn_synergistic_progressive_inference_of_neural_networks_over_device_and_cloud.pdf">SPINN: Synergistic Progressive Inference of Neural Networks over Device and Cloud</a></em>,
						<strong>26th Annual International Conference on Mobile Computing and Networking (MobiCom), 2020.</strong> [<a href="papers/spinn2020mobicom.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2008.06402">preprint</a> | <a href="https://dl.acm.org/doi/10.1145/3372224.3419194">link</a> | <a href="https://youtu.be/wmCNVt-NQd0">video</a>]
					</p>
					<p>
						Royson Lee, Lukasz Dudziak, Mohamed S. Abdelfattah, <strong>Stylianos I. Venieris</strong>, Hyeji Kim, Hongkai Wen and Nicholas D. Lane<br/>
						<em><a href="papers/[2020]_eccv_journey_towards_tiny_perceptual_super_resolution.pdf">Journey Towards Tiny Perceptual Super-Resolution</a></em>,
						<strong>16th European Conference on Computer Vision (ECCV), 2020.</strong> [<a href="papers/tinysr2020eccv.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2007.04356">preprint</a> | <a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/html/5305_ECCV_2020_paper.php">link</a> | <a href="https://github.com/royson/tpsr/">open-source</a>] <!--| <a href="https://github.com/ICIdsl/pytorch_training.git">open-source repo</a>]-->
					</p>
					<p>
						Aditya Rajagopal, Diederik A. Vink, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2020]_icml_muppet_a_precision_switching_strategy_for_quantised_fixed_point_training_of_cnns.pdf"-->Multi-Precision Policy Enforced Training (MuPPET): A precision-switching strategy for quantised fixed-point training of CNNs</a></em>,
						<strong>37th International Conference on Machine Learning (ICML), 2020.</strong> [<!--a href="papers/kouris2020date.bibtex">bibtex</a--><a href="https://arxiv.org/abs/2006.09049">preprint</a> | <a href="https://proceedings.icml.cc/paper/2020/hash/dfb84a11f431c62436cfb760e30a34fe-Abstract.html">link</a> | <a href="https://github.com/ICIdsl/muppet">open-source repo</a>]
					</p>
					<p>
						Diederik A. Vink, Aditya Rajagopal, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2020]_fpl_caffe_barista_brewing_caffe_with_fpgas_in_the_training_loop.pdf"-->Caffe Barista: Brewing Caffe with FPGAs in the Training Loop</a></em>,
						<strong>30th International Conference on Field-Programmable Logic and Applications (FPL), 2020.</strong> [<!--a href="papers/kouris2020date.bibtex">bibtex</a--><a href="https://arxiv.org/abs/2006.13829">preprint</a> | <a href="https://ieeexplore.ieee.org/abstract/document/9221618">link</a> | <a href="https://github.com/ICIdsl/caffe_fpga.git">open-source repo</a>]
					</p>
					<p>
						Alexandros Kouris, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2020]_date_a_thrpt_latency_cooptimised_cascade_of_cnn_classifiers.pdf">A Throughput-Latency Co-Optimised Cascade of Convolutional Neural Network Classifiers</a></em>,
						<strong>International Conference on Design, Automation and Test in Europe (DATE), 2020.</strong> [<a href="papers/kouris2020date.bibtex">bibtex</a> | <a href="https://ieeexplore.ieee.org/abstract/document/9116248">link</a>]
					</p>
					<p>
						Alexander Montgomerie-Corcoran, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2019]_fpt_power_aware_fpga_mapping_of_cnns.pdf">Power-Aware FPGA Mapping of Convolutional Neural Networks</a></em>,
						<strong>IEEE International Conference on Field-Programmable Technology (FPT), 2019.</strong> [<a href="papers/montgom2019fpt.bibtex" target="_blank">bibtex</a> | <a href="https://ieeexplore.ieee.org/document/8977845">link</a>]
					</p>
					<p>
						Royson Lee*, <strong>Stylianos I. Venieris*</strong>, Lukasz Dudziak, Sourav Bhattacharya and Nicholas D. Lane<br/>
						<em><a href="papers/[2019]_mobicom_mobisr_efficient_on_device_super_resolution_through_heterogeneous_mobile_processors.pdf">MobiSR: Efficient On-Device Super-resolution through Heterogeneous Mobile Processors</a></em>,
						<strong>25th Annual International Conference on Mobile Computing and Networking (MobiCom), 2019.</strong> [<a href="papers/lee2019mobicom.bibtex">bibtex</a> | <a href="https://dl.acm.org/citation.cfm?id=3345455">link</a> | <a href="https://youtu.be/UJ0LtsA3Eoo">video</a>]
					</p>
					<p>
						Alexandros Kouris, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
						<em><a href="papers/[2019]_isvlsi_towards_efficient_onboard_deployment_of_dnns_on_intelligent_autonomous_systems.pdf">Towards Efficient On-Board Deployment of Deep Neural Networks on Intelligent Autonomous Systems</a></em>,
						<strong>IEEE Computer Society Annual Symposium on VLSI (ISVLSI), 2019.</strong> [<a href="papers/[2019]_isvlsi_towards_efficient_onboard_deployment_of_dnns_on_intelligent_autonomous_systems.pdf">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8839367">link</a>]
					</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/[2018]_fpl_fcnnx_mapping_multiple_cnns_on_fpgas.pdf">f-CNN<sup>x</sup>: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs</a></em>,
          				<strong>28th International Conference on Field Programmable Logic and Applications (FPL), 2018.</strong> [<a href="papers/sv2018fpl.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/1805.10174" target="_blank">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8533527">link</a>]
          			</p>
					<p>
          				Alexandros Kouris, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/[2018]_cascadecnn_pushing_the_performance_limits_of_quantisation_in_cnns.pdf">CascadeCNN: Pushing the Performance Limits of Quantisation in Convolutional Neural Networks</a></em>,
          				<strong>28th International Conference on Field Programmable Logic and Applications (FPL), 2018.</strong> [<a href="papers/kouris2018fpl.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/1807.05053">preprint</a> | <a href="https://ieeexplore.ieee.org/document/8533486">link</a>]
          			</p>
					
					<p>
          				Alexandros Kouris, <strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="http://www.sysml.cc/doc/114.pdf">CascadeCNN: Pushing the performance limits of quantisation</a></em>,
          				<strong>MLSys, 2018.</strong> [<a href="papers/cascadecnn2018sysml.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/1805.08743">link</a>]
          			</p>
					<p>
          				Michalis Rizakis, <strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2018arc.pdf">Approximate FPGA-based LSTMs under Computation Time Constraints</a></em>,
          				<strong>14th International Symposium on Applied Reconfigurable Computing (ARC), 2018.</strong> <strong>(Best paper nominee)</strong> [<a href="papers/sv2018arc.bibtex" target="_blank">bibtex</a> | <a href="https://arxiv.org/abs/1801.02190">link</a>]
          			</p>
					<p>
          				Christos Kyrkou, George Plastiras, <strong>Stylianos I. Venieris</strong>, Theocharis Theocharides and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/[2018]_date_dronet_efficient_cnn_detector_for_rt_uav_applications.pdf">DroNet: Efficient Convolutional Neural Network Detector for Real-Time UAV Applications</a></em>,
          				<strong>International Conference on Design, Automation and Test in Europe (DATE), 2018.</strong> [<a href="papers/sv2018date.bibtex" target="_blank">bibtex</a> | 
						<a href="https://ieeexplore.ieee.org/document/8342149/">link</a> | <a href="https://www.youtube.com/watch?v=xBUDgElhdcw">demo</a>]
          			</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="https://tinyurl.com/y9rhz7ls">Latency-Driven Design for FPGA-based Convolutional Neural Networks</a></em>, 
          				<strong>27th International Conference on Field Programmable Logic and Applications (FPL), 2017.</strong> [<a href="papers/sv2017fpl.bibtex" target="_blank">bibtex</a> | <a href="http://ieeexplore.ieee.org/document/8056828/">link</a>] <!--(<a href="papers/sv2017fpga_poster.pdf">poster</a>, <a href="papers/sv2017fpga.bibtex">bibtex</a>, 
						<a href="http://dl.acm.org/citation.cfm?doid=3020078.3021791">link</a>) -->
          			</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2017fpga_poster.pdf">fpgaConvNet: Automated Mapping of Convolutional Neural Networks on FPGAs</a></em>, 
          				<strong>ACM/SIGDA International Symposium on Field-Programmable Gate Arrays (FPGA), 2017.</strong> [<a href="papers/sv2017fpga_poster.pdf">poster</a> | <a href="papers/sv2017fpga.bibtex" target="_blank">bibtex</a> |
						<a href="http://dl.acm.org/citation.cfm?doid=3020078.3021791">link</a>]
          			</p>
					
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2016fccm.pdf">fpgaConvNet: A Framework for Mapping Convolutional Neural Networks on FPGAs</a></em>, 
          				<!--strong>FCCM 2016</strong--><strong>24th IEEE International Symposium on Field-Programmable Custom Computing Machines (FCCM), 2016.</strong> [<a href="papers/sv2016fccm_slides.pdf">slides</a> | 
						<a href="papers/sv2016fccm.bibtex" target="_blank">bibtex</a> |
						<a href="http://ieeexplore.ieee.org/document/7544745/">link</a> | <a href="fpgaConvNet.html">benchmarks</a>]
          			</p>

          			<p>
          				<strong>Stylianos I. Venieris</strong>, Grigorios Mingas and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2015fpl.pdf">Towards Heterogeneous Solvers for Large-Scale Linear Systems</a></em>, 
          				<strong>25th International Conference on Field Programmable Logic and Applications (FPL), 2015.</strong> [<a href="papers/sv2015fpl_slides.pdf">slides</a> | 
          				<a href="papers/sv2016fpl.bibtex" target="_blank">bibtex</a> | <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7293751">link</a>]
          			</p>
					
					<h4>Refereed Workshop Papers</h4>
					<p>
						Ilias Leontiadis*, Stefanos Laskaridis*, <strong>Stylianos I. Venieris*</strong> and Nicholas D. Lane<br/>
						<em><a href="papers/[2021]_hotmobile_its_always_personal_using_early_exits_for_efficient_cnn_personalisation.pdf">It's always personal: Using Early Exits for Efficient On-Device CNN Personalisation</a></em>,
						<strong>22nd International Workshop on Mobile Computing Systems and Applications (HotMobile), 2021.</strong> [<!--a href="papers/hapi2020iccad.bibtex">bibtex</a | --><a href="https://arxiv.org/abs/2102.01393">preprint</a> | <a href="https://dl.acm.org/doi/10.1145/3446382.3448359">link</a> | <a href="https://youtu.be/voOJg-NcUzA">video</a>]
					</p>
					<p>
						Royson Lee*, <strong>Stylianos I. Venieris*</strong> and Nicholas D. Lane<br/>
						<em><a href="papers/[2020]_distributedml_neural_enhancement_in_content_delivery_systems_state_of_the_art_and_future_directions.pdf">Neural Enhancement in Content Delivery Systems: The State-of-the-Art and Future Directions</a></em>,
						<strong>1st Workshop on Distributed Machine Learning (DistributedML), CoNEXT, 2020.</strong> [<a href="papers/neuralcds2020distributedml.bibtex">bibtex</a> | <a href="https://arxiv.org/abs/2010.05838">preprint</a> | <a href="https://dl.acm.org/doi/10.1145/3426745.3431336">link</a>] <!--| <a href="https://github.com/ICIdsl/pytorch_training.git">open-source repo</a>]-->
					</p>
					<p>
						Mario Almeida*, Stefanos Laskaridis*, Ilias Leontiadis*, <strong>Stylianos I. Venieris*</strong> and Nicholas D. Lane<br/>
						<em><a href="https://arxiv.org/abs/1905.07346">EmBench: Quantifying Performance Variations of Deep Neural Networks across Modern Commodity Devices</a></em>,
						<strong>3rd International Workshop on Embedded and Mobile Deep Learning (EMDL), MobiSys, 2019.</strong> [<!--a href="papers/sv2018csur.bibtex">bibtex</a> | --><a href="https://arxiv.org/abs/1905.07346">preprint</a>]
					</p>
					<p>
						<strong>Stylianos I. Venieris</strong>, Alexandros Kouris and Christos-Savvas Bouganis<br/>
						<em><a href="https://www.sigmobile.org/mobisys/2018/workshops/deepmobile18/papers/Deploying_Deep_Neural_Networks_in_the_Embedded_Space.pdf"-->Deploying Deep Neural Networks in the Embedded Space</a></em>,
						<strong>2nd International Workshop on Embedded and Mobile Deep Learning (EMDL), MobiSys, 2018.</strong> [<!--a href="papers/sv2018csur.bibtex">bibtex</a> | --><a href="http://arxiv.org/abs/1806.08616">link</a> | <a href="papers/EMDL_slides_final.pdf">slides</a>]
					</p>
					<p>
          				<strong>Stylianos I. Venieris</strong> and Christos-Savvas Bouganis<br/>
          				<em><a href="papers/sv2017nips.pdf">fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural Networks on Embedded FPGAs</a></em>,
          				<strong>Workshop on Machine Learning on the Phone and other Consumer Devices (MLPCD), NeurIPS, 2017.</strong> [<a href="papers/sv2017nips.bibtex" target="_blank">bibtex</a> | 
						<a href="http://arxiv.org/abs/1711.08740">link</a> | <a href="papers/sv2017nips_mlpcd_slides.pdf">slides</a>]
          			</p>
		  			</div>
        		</div>
      		</div>

      		<div class="footer discrete">
        		<p>&copy; Stylianos Venieris 2022</p>
      		</div>

    	</div> <!-- /container -->

    	<!-- Latest compiled and minified JavaScript -->
    	<script src="https://code.jquery.com/jquery-1.11.0.min.js"></script>
		<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
		<!--script src="http://code.jquery.com/ui/1.10.3/jquery-ui.min.js"></script-->
	</body>
</html>
